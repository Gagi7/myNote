## 链路追踪技术

对于没有接触过这个词的同学可能很蒙蔽，什么是链路追踪技术？干吗用呢？

其实链路追踪技术理解起来非常简单，我们看一下这张图

<img src="image/image-20201215140937165.png" alt="image-20201215140937165" style="zoom:80%;" />

看了这张图是不是头皮发麻呢？这就是企业中微服务间的调用关系，看到这张图应该就知道了，我们需要一种技术来管理它，人工管理调用关系是不可能的，就算你想要人工管理，那么比如你负责的服务是购物车服务，你知道有用户服务调用了你，但是对于用户服务于其他服务的调用关系你不会特别清楚的，所以这种间接调用关系非常难梳理。

这时就需要我们的链路追踪技术了，来管理各微服务间的调用关系。

链路追踪技术也不仅仅只有这一种作用，还有一些好用的功能

<img src="image/image-20201215141558868.png" alt="image-20201215141558868" style="zoom:80%;" />

- `分布式`：链路追踪可以从分布式环境中获取所有节点的信息进行管理
- `Timing信息`：就是整个调用链路每个微服务模块所耗费的时间，比如用户从点击下单到下单成功，购物车，订单，用户微服务各个的耗费时间以及总时长等
- `定位链路`：每条链路都有自己的ID，管理人员只需要通过查询这个ID就可以获取某条链路的所有调用情况，可以非常方便的查询问题
- `信息收集展示`：信息收集完后，还需要可视化的展示出来，更好查看

可以看到，链路追踪技术所提供的功能点很多，说明它需要提供的也这么多，那么它就不是一种技术直接实现的，而是多种中间件配合实现

## Sleuth介绍

Sleuth意思为大侦探，顾名思义，Sleuth就是沿着从上游到下游的请求，找到所有关联关系，也就是我们的链路追踪技术。

### Sleuth的功能

最核心就是链路追踪技术，在用户请求发起后，所经过的所有服务都会被Sleuth梳理出来

<img src="image/image-20201215150108812.png" alt="image-20201215150108812" style="zoom:80%;" />

比如：服务A调用服务D，服务D又调用服务C，C又调用了F，那么Sleuth就会通过一种打标记的机制，对所有这次请求访问的服务打上标记，我们只需要拿到这个标记，就可追踪到这次请求所有服务调用。

Sleuth还可以完成一些其他的功能：

- **线上故障排查**：之前我们说过，通过Tracking ID就可以获取某条请求链路的所有服务信息，那么我们就可以看到出错异常是在哪个服务生成的，就很方便进行故障排查
- **性能分析**：对于每天链路的每个服务请求，都会保存它的响应时间等信息，通过响应时间就可以推断哪个服务调用时间过长，就可以进行优化
- **依赖梳理**：当服务节点过多，服务与服务间的依赖调用错综复杂，就可以依靠Sleuth来梳理依赖关系
- **链路优化**：比如我们有很多推荐算法，哪种推荐算法会让用户的下单率高，就可以通过Sleuth来观察，找到转化率最高的为以后产品设计打下基础

### Sleuth的优势

链路追踪技术肯定不少，Sleuth又有什么优点呢？主要是他的两大设计原则

- **无业务侵入**：Sleuth不需要你在业务代码中进行任何改动，就可以静默接入链路追踪技术，这个可以说是非常棒的开源组件的设计理念了
- **高性能**：其实，对于日志来说，一般来说在业务代码中加入完整的log（10行代码里有2行log），会影响5%左右的接口性能，因此，Sleuth也是基于对Log埋点实现追踪，也多多少少会影响一些性能，但是对Sleuth来说，力求对性能影响最小，同时还提供了“采样率配置”降低开销（比如开发人员可以设置只对20%请求进行采样）

### Sleuth的体系架构

Sleuth底层是依靠Log系统实现业务埋点的：

<img src="image/image-20201215152205438.png" alt="image-20201215152205438" style="zoom:80%;" />

每个服务都有Log组件，Sleuth集成之后，会将链路信息传递给Log组件，在每行日志前打印这些信息，主要会记录几个关键信息：

- 链路ID：当前请求整条链路的ID，如上图，在ABC服务流转间，它的Tracking ID是不变的，这就是链路ID
- 单元ID：因为一次链路请求会访问不同的服务节点，所以每个服务节点有自己的单元ID来区分不同服务，并且会记录请求来自哪里，也就是上游服务，可以通过图中的Parent看到

通过我们的介绍，可以看出Sleuth主要依靠在Log埋点，实现对链路的记录，并且埋点具有特殊的一些信息需要打印，那么就引入一个问题，Sleuth如何进行数据埋点呢？

- Log系统集成：如何让埋点信息加入到业务Log中？
- 埋点信息传递：服务调用间，如何把链路ID等信息传递到下游？

我们针对这两个问题，来展开了解

### Log系统集成

Sleuth既然要切入Log打印信息，我们就先了解一些Log组件时如何打印信息的

<img src="image/image-20201215160621311.png" alt="image-20201215160621311" style="zoom:80%;" />

这里主要有两个重要组件，LogFormat和MDC，当我们使用"[log.info](http://log.info/)"打印日志的时候，Log组件会将“写入”动作封装成一个LogEvent事件，而这个事件的具体表现形式由Log Format和MDC共同控制，Format决定了Log的输出格式，而MDC决定了输出什么内容。

**Log Format Pattern**

Log组件定义了日志输出格式，这和我们平时使用“String.format”的方式差不多，集成了Sleuth后的Log输出格式是下面这个样子：

```
"%5p [sleuth-traceA,%X{X-B3-TraceId:-},%X{X-B3-SpanId:-},%X{X-Span-Export:-}]"
```

上面有几个X开头的占位符，这就是我们需要写入Log的链路追踪信息了。至于这几个符号分别对应链路信息的哪部分，在之后介绍

**MDC**

MDC是通过`InheritableThreadLocal`来实现的，它可以携带当前线程的上下文信息。它的底层是一个Map结构，存储了一系列Key-Value的值。Sleuth就是借助Spring的AOP机制，在方法调用的时候配置了切面，将链路追踪数据加入到了MDC中，这样在打印Log的时候，就能从MDC中获取这些值，填入到Log Format中的占位符里

由于MDC基于InheritableThreadLocal而不是ThreadLocal实现，因此假如在当前线程中又开启了新的子线程，那么子线程依然会保留父线程的上下文信息

### Sleuth数据结构

咦？我们不应该看第二个问题埋点信息传递吗？怎么跳到数据结构了？

因为埋点信息传递前必须先了解数据结构，之前我们一直说Sleuth会生成一些信息，在埋点的时候，我们知道的有Tracking ID，那么具体有什么信息呢？主要有两大长老：

- **Trace**：从头到尾贯穿链路的ID，Trace ID
- **Span**：标识一个基本的工作单元，每个单元都有独一无二的ID，就比如服务A调用服务B，这就是一个事件，就需要一个工作单元SPAN来记录。Span不单单只是一个ID，它还包含一些其他信息，比如时间戳，它标识了一个事件从开始到结束经过的时间，我们可以用这个信息来统计接口的执行时间。每个Span还有一系列特殊的“标记”，也就是接下来要介绍的`Annotation`，它标识了这个Span在执行过程中发起的一些特殊事件。

**Annotation**

一个Span会包含多个Annotation，每个Annotation表示一个特殊的事件：

- CS（Client Sent）：客户端发送一个调用请求
- SR（Server Received）：服务端接收请求进行处理
- SS（Server Sent）：服务端处理完毕，发送Response给客户端
- CR（Client Received）：客户端接收到Response

每个Annotation同样有一个时间戳字段，这样我们就能分析一个Span内部每个事件的起始和结束时间

是不是很清晰呢？如果还觉得不清晰，我们看看下面这张官方图：

<img src="image/Sleuth.png" alt="image-20201215162544003" style="zoom:100%;" />

我们一点点来看：

1. 首先，图中有两个Service，代表两个服务节点
2. 除了一开始http的请求外，每个Span都具有相同的Trace ID=X，说明为一个整的调用链路
3. 浅蓝色的Span对应http请求与Service1的调用事件，所以有相同的Span ID，事件为SR和SS，服务端接收HTTP请求以及最后的Response响应
4. 蓝色Span对应Service1对Service2的请求，具有4个Annotation事件，并且为一个Span ID，说明是一个整的Span，包含了CS，SR，SS，CR
5. 绿色的Span是Service2内部业务处理，所以又是一个Span，因为是Service2内部方法执行，所以该Span会打印在Service2的日志中

看完这个，是不是很清晰了呢？Trace ID会伴随整个Http请求，而Span对应一次服务调用，不同服务间调用请求具有不同的Span

### 埋点信息传递

我们知道了Trace ID和Span ID，眼下的问题就是如何在不同服务节点之间传递这些ID。我想这一步大家很容易猜到是怎么做的，因为在Eureka的服务治理下所有调用请求都是基于HTTP的，那我们的链路追踪ID也一定是HTTP请求中的一部分。可是把ID加在HTTP哪里好呢？Body里可以吗？NoNoNo，一来GET请求压根就没有Body，二来加入Body还有可能影响后台服务的反序列化。那加在URL后面呢？似乎也不妥，因为某些服务组件对URL的长度可能做了限制（比如Nginx可以设置最大URL长度）。

那剩下的只有Header了！**Sleuth正是通过Filter向Header中添加追踪信息**，我们来看下面表格中Header Name和Trace Data的对应关系：

| Header Name       | Trace Data                          | 含义           |
| ----------------- | ----------------------------------- | -------------- |
| X-B3-TraceId      | Trace ID                            | 整个链路的ID   |
| X-B3-SpanId       | Span ID                             | 当前Span的ID   |
| X-B3-ParentSpanId | Parent Span ID                      | 前一个Span的ID |
| X-Span-Export     | Can be exported for sampling or not | 是否可以被采样 |

在调用下一个服务的时候，Sleuth会在当前的Request Header中写入上面的信息，这样下游系统就很容易识别出当前Trace ID以及它的前置Span ID是什么

接着，我们通过demo，更直观的利用代码了解Sleuth

## Sleuth Demo

接着就是我们的Demo实现环节了，对于Sleuth的实现真得非常非常简单，我们需要创建两个module，`sleuth-traceA`和`sleuth-traceB`，然后A调用B才看看日志中的链路情况

首先我们创建traceA

**1.创建module添加依赖**

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
    <!--Sleuth-->
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-sleuth</artifactId>
    </dependency>
</dependencies>
```

**2.创建主程序类并直接添加controller方法**

```java
@SpringBootApplication
@RestController
@Slf4j
public class SleuthApplication {

    @LoadBalanced
    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

    @Autowired
    private RestTemplate restTemplate;

    @GetMapping("/traceA")
    public String traceA(){
        log.info("------------ Trace A --------------");
        return restTemplate.getForObject("http://SLEUTH-TRACEB/traceB",String.class);
    }

    public static void main(String[] args) {
        SpringApplication.run(SleuthApplication.class,args);
    }
}
```

**3.创建配置文件并配置**

```yml
server:
  port: 62001
spring:
  application:
    name: sleuth-traceA
eureka:
  client:
    service-url:
      defaultZone: http://localhost:22222/eureka
management:
  security:
    enabled: true
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      show-details: always
```



创建完TraceA后，TraceB的创建过程是一模一样的，只不过controller需要修改一下

```java
@GetMapping("/traceB")
public String traceB(){
    log.info("------------ Trace B --------------");
    return "traceB";
}
```

直接return就好了

然后就可以测试了，请求http://localhost:62001/traceA，查看日志

![image-20201218101554908](image/image-20201218101554908.png)

![image-20201218101604761](image/image-20201218101604761.png)

我们主要看错误等级后的中括号里的几个数据，分为：

- 服务名称
- Trace ID：TraceA和TraceB的Trace ID是相同的
- Span ID：TraceA和TraceB的Span ID是不同的
- 是否采集：这个采集是后面说到的，用来对日志进行收集配合其他中间件，将其可视化出来

这里我们说到了采集，那么后面就看一下Sleuth日志信息采集是怎么回事